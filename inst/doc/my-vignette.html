<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Keiichiro Hijikata" />

<meta name="date" content="2023-11-08" />

<title>variationalDCM vignette</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>







<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">variationalDCM vignette</h1>
<h4 class="author">Keiichiro Hijikata</h4>
<h4 class="date">2023-11-08</h4>



<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p><code>variationalDCM</code> is an R package that performs
recently-developed variational Bayesian inference for diagnostic
classification models (DCMs), which are a family of statistical models
for collecting, analyzing, and reporting diagnostic information in
Education and Psychology.</p>
</div>
<div id="dcms" class="section level1">
<h1>DCMs</h1>
<p>Diagnostic assessment is a type of evaluation process that is used to
diagnose the respondent’s current status of knowledge, skills,
abilities, or other characteristics in a particular domain. These
underlying traits are collectively called <strong>attributes</strong> in
the literature of DCMs. By identifying the mastery status of each
respondent, the diagnostic results can help tailor instruction,
intervention, and support to address the specific needs of the
respondent.</p>
<p>DCMs have a lot of sub-models and we introduce some models related to
this package.</p>
<div id="dina-model" class="section level2">
<h2>DINA model</h2>
<p>The deterministic input noisy AND gate (DINA) model is representative
of a non-compensatory model, which assumes that respondents must have
mastered all the required attributes associated with a particular item
to respond correctly.</p>
</div>
<div id="dino-model" class="section level2">
<h2>DINO model</h2>
<p>The deterministic input noisy OR gate (DINO) model is another
well-known model. In contrast to the DINA model, the DINO model is one
of the compensatory models, which assumes that obtaining a correct
response to an item necessitates mastery of at least one of the relevant
attributes.</p>
</div>
<div id="saturated-dcm" class="section level2">
<h2>saturated DCM</h2>
<p>The saturated DCM is a saturated formulation of DCMs, which contain
as many parameters as possible under the given item-attribute
relationship. This generalized models include the DINA and DINO models
as the most parsimonious special cases, as well as many other sub-models
that differ in their degree of generalization and parsimony.</p>
</div>
<div id="multiple-choices-dina-model" class="section level2">
<h2>multiple choices DINA model</h2>
<p>The multiple-choice format, in which respondents are required to
select the most appropriate option from the given multiple options, is
one of the most widely used formats of items in assessments. To provide
a comprehensive and informative diagnostic assessment based on the
responses for multiple-choice items, the multiple-choice DINA (MC-DINA)
model was developed as an extension of the DINA model, which was
originally for binary response data.</p>
</div>
<div id="hidden-markov-dcm" class="section level2">
<h2>hidden Markov DCM</h2>
<p>The hidden Markov DCM (HM-DCM) is an extended model to the
longitudinal item response data to model the time course of learning
multiple attributes. The HM-DCM allows researchers to model the
transition in mastery statuses over time.</p>
</div>
</div>
<div id="functions" class="section level1">
<h1>Functions</h1>
<p>The below table summarizes the five functions that the
<code>variationalDCM</code> package provides, corresponding models, and
reference information for the papers that proposed their variational
Bayesian estimation.</p>
<table>
<colgroup>
<col width="24%" />
<col width="36%" />
<col width="38%" />
</colgroup>
<thead>
<tr class="header">
<th>Function Name</th>
<th>Functionality</th>
<th>Reference</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>dina()</code></td>
<td>the DINA model</td>
<td>Yamaguchi &amp; Okada (2020b)</td>
</tr>
<tr class="even">
<td><code>dino()</code></td>
<td>the DINO model</td>
<td>slight modification of <code>dina()</code></td>
</tr>
<tr class="odd">
<td><code>satu_dcm()</code></td>
<td>the saturated DCM</td>
<td>Yamaguchi &amp; Okada (2020a)</td>
</tr>
<tr class="even">
<td><code>mc_dina()</code></td>
<td>the multiple-choice DINA model</td>
<td>Yamaguchi (2020)</td>
</tr>
<tr class="odd">
<td><code>hm_dcm()</code></td>
<td>the hidden Markov DCM</td>
<td>Yamaguchi &amp; Martinez (2023)</td>
</tr>
</tbody>
</table>
<p>details of the above functions such as arguments and returns are
given in .R script of each function.</p>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<ul>
<li><p>Oka, M., &amp; Okada, K. (2023). Scalable Bayesian Approach for
the Dina Q-Matrix Estimation Combining Stochastic Optimization and
Variational Inference. <em>Psychometrika</em>, 88, 302–331. <a href="https://doi.org/10.1007/s11336-022-09884-4" class="uri">https://doi.org/10.1007/s11336-022-09884-4</a></p></li>
<li><p>Yamaguchi, K., &amp; Okada, K. (2020b). Variational Bayes
Inference for the DINA Model. <em>Journal of Educational and Behavioral
Statistics</em>, 45(5), 569–597. <a href="https://doi.org/10.3102/1076998620911934" class="uri">https://doi.org/10.3102/1076998620911934</a></p></li>
<li><p>Yamaguchi, K., Okada, K. (2020a). Variational Bayes Inference
Algorithm for the Saturated Diagnostic Classification Model.
<em>Psychometrika</em>, 85(4), 973–995. <a href="https://doi.org/10.1007/s11336-020-09739-w" class="uri">https://doi.org/10.1007/s11336-020-09739-w</a></p></li>
<li><p>Yamaguchi, K. (2020). Variational Bayesian inference for the
multiple-choice DINA model. <em>Behaviormetrika</em>, 47(1), 159-187. <a href="https://doi.org/10.1007/s41237-020-00104-w" class="uri">https://doi.org/10.1007/s41237-020-00104-w</a></p></li>
<li><p>Yamaguchi, K., &amp; Martinez, A. J. (2023). Variational Bayes
inference for hidden Markov diagnostic classification models.
<em>British Journal of Mathematical and Statistical Psychology</em>. <a href="https://doi.org/10.1111/bmsp.12308" class="uri">https://doi.org/10.1111/bmsp.12308</a></p></li>
</ul>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
